{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca3bdc7",
   "metadata": {},
   "source": [
    "# single animal alignment functional 2p -> anatomy\n",
    "## (obsolete, have batch version)\n",
    "## (below are useful snippets for napari hyperstack movie generation)\n",
    "\n",
    "Image stack alignment (moving -> fixed)\n",
    "- For each moving plane, find best (x, y, z, scale) in fixed stack.\n",
    "- Coarse-to-fine pyramid with template matching + subpixel refinement.\n",
    "- Outputs per-plane mapping in pixels (x,y) in fixed coords, z index/µm, and scale.\n",
    "- at the end, assemble a hyperstack for napari movie generation. this could be done better.\n",
    "\n",
    "Johannes Larsch 20250916"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup & imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, math, warnings, json\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "# Get parent of the notebook dir (project_root)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "# Add sibling directory \"src\" to sys.path\n",
    "sys.path.append(os.path.join(project_root, \"src\"))\n",
    "\n",
    "import alignSubstackUtils as asu\n",
    "import saveFunctionalProjections as sfp\n",
    "from skimage.transform import rotate as sk_rotate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "\n",
    "_HAS_SKIMAGE = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS PATH ===\n",
    "#START_FOLDER = Path(r\"Y:/Danin/imaging/temp/planes/\")\n",
    "START_FOLDER = Path(r\"D:/i/danin_tests/temp/planes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38717c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotation_angle = 140  # degrees, e.g. 0, 90, 180, 270\n",
    "sfp.save_max_avg_projections(START_FOLDER, rotation_angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c27164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcStacks=sfp.collect_tiff_files(START_FOLDER)\n",
    "funcStacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfa6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ### Example usage\n",
    "# Replace the dummy arrays with your actual data (NumPy arrays loaded from TIFF, NIfTI, HDF5, etc.)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# # Run registration\n",
    "# df_results = register_moving_stack(\n",
    "#     fixed_stack,\n",
    "#     moving_stack,\n",
    "#     fixed_z_spacing_um=1.0,\n",
    "#     scale_range=(0.35, 1.0),   # moving is more zoomed-in -> usually < 1.0\n",
    "#     n_scales=11,\n",
    "#     z_stride_coarse=4,\n",
    "#     z_refine_radius=3,\n",
    "#     pyramid_downscale=2,\n",
    "#     pyramid_min_size=160,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# display(df_results)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Notes & tips\n",
    "# - If the moving FOV is substantially smaller, keep `scale_range` < 1 (e.g., 0.2–0.8).\n",
    "# - If computation is slow, increase `z_stride_coarse` or `pyramid_min_size`.\n",
    "# - For very noisy data, consider pre-filtering with a small Gaussian before normalization.\n",
    "# - `ncc_score` near 1.0 indicates a strong match; inspect low scores visually.\n",
    "# - Coordinates (x_px, y_px) are given in **fixed** image pixels at full resolution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "moving_p = Path(r\"Y:/Danin/imaging/temp/planes/projections/avg_projections.tif\")\n",
    "fixed_p = Path(r\"Y:/Danin/imaging/temp/f38_anatomy_00001_rotate_8b.tif\")\n",
    "fixed_stack = tifffile.imread(fixed_p)   # shape: (Zf, Yf, Xf), spacing 1 µm\n",
    "moving_stack = tifffile.imread(moving_p) # shape: (Zm, Ym, Xm), spacing 4–15 µm between planes\n",
    "\n",
    "\n",
    "df_results = asu.register_moving_stack(\n",
    "    fixed_stack, \n",
    "    moving_stack,\n",
    "    fixed_z_spacing_um=1.0,     # spacing between planes in the fixed stack (µm)\n",
    "    scale_range=(0.6, 1.0),   # expected relative zoom (moving→fixed); narrower range boosts SNR\n",
    "    n_scales=10,                 # number of discrete scales to test between scale_range\n",
    "    pyramid_downscale=2,      # downscale factor per pyramid level (smaller = finer refinement)\n",
    "    pyramid_min_size=140,       # stop pyramid when min dimension < this; ensures at least 1 coarse level\n",
    "    z_stride_coarse=2,          # step size for z-search at coarsest level (higher = faster, lower = more exhaustive)\n",
    "    z_refine_radius=3,          # number of planes around best z to test at finer levels\n",
    "    verbose=True,               # print per-plane progress and NCC scores\n",
    ")\n",
    "\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f62654",
   "metadata": {},
   "outputs": [],
   "source": [
    "asu.interactive_checker(fixed_stack, moving_stack, df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2bc9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_p = Path(r\"Y:/Danin/imaging/temp/planes/projections/max_projections.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98865ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fb0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Usage =====\n",
    "# fixed_stack: your reference stack (Zf, Yf, Xf) — you likely already have it in memory\n",
    "# funcStacks: list of paths, one per moving plane (e.g., same order as moving_stack planes)\n",
    "# Example:\n",
    "# hyper = build_registered_hyperstack(\n",
    "#     funcStacks=funcStacks,\n",
    "#     df_results=df_results,\n",
    "#     fixed_stack_shape=fixed_stack.shape,\n",
    "#     dtype=np.float32,\n",
    "#     save_path=\"registered_hyperstack_tzyx.tif\"   # or None to keep in memory only\n",
    "# )\n",
    "# hyper.shape  # -> (100, Zf, Yf, Xf)\n",
    "\n",
    "save_path = START_FOLDER / \"hyperstack_new.tif\"\n",
    "Zf, Yf, Xf = fixed_stack.shape  # (216, 512, 512)\n",
    "\n",
    "\n",
    "hyper = asu.build_hyperstack_uint8_in_memory(\n",
    "    funcStacks=funcStacks,\n",
    "    df_results=df_results,\n",
    "    fixed_stack_shape=(Zf, Yf, Xf),\n",
    "    use_percentiles=(1,99.9),                 # or (1, 99) for robust scaling\n",
    "    save_path=save_path # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6773c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "\n",
    "def _scale_to_uint8_percentiles(vol, p_low=0.1, p_high=99.1):\n",
    "    volf = vol.astype(np.float32, copy=False)\n",
    "    vmin, vmax = np.percentile(volf, [p_low, p_high])\n",
    "    eps = 1e-6\n",
    "    out = (volf - vmin) * (255.0 / max(vmax - vmin, eps))\n",
    "    return np.clip(out, 0, 255).astype(np.uint8, copy=False)\n",
    "\n",
    "def build_5d_hyperstack_fixed_plus_func(\n",
    "    fixed_stack,           # (Z, Y, X) — any dtype\n",
    "    func_hyper_path,       # path to previously saved functional hyperstack (T, Z, Y, X) uint8\n",
    "    out_path,              # output OME-TIFF path\n",
    "    T_expected=100\n",
    "):\n",
    "    # ----- load / check inputs -----\n",
    "    Zf, Yf, Xf = fixed_stack.shape\n",
    "    func = tiff.imread(func_hyper_path)   # expect (T, Z, Y, X), uint8\n",
    "    if func.ndim != 4:\n",
    "        raise ValueError(f\"Functional hyperstack must be (T,Z,Y,X); got {func.shape}\")\n",
    "    T_func, Z_func, Y_func, X_func = func.shape\n",
    "    if T_func != T_expected:\n",
    "        raise ValueError(f\"T mismatch: functional has T={T_func}, expected {T_expected}\")\n",
    "    if (Z_func, Y_func, X_func) != (Zf, Yf, Xf):\n",
    "        raise ValueError(f\"Spatial mismatch: func (Z,Y,X)={func.shape[1:]}, fixed={(Zf,Yf,Xf)}\")\n",
    "\n",
    "    # ----- channel 1: fixed stack scaled to uint8 (0.1–99.1 pct), repeated along time -----\n",
    "    fixed_u8 = _scale_to_uint8_percentiles(fixed_stack, 0.1, 99.1)   # (Z,Y,X) -> uint8\n",
    "    # Repeat along time to shape (T, Z, Y, X)\n",
    "    c1 = np.broadcast_to(fixed_u8, (T_expected, Zf, Yf, Xf)).copy()\n",
    "\n",
    "    # ----- channel 2: functional hyperstack -----\n",
    "    c2 = func.astype(np.uint8, copy=False)  # should already be uint8 from your previous step\n",
    "\n",
    "    # ----- stack into (T, C, Z, Y, X) -----\n",
    "    hyper5 = np.stack([c1, c2], axis=1)  # (T, 2, Z, Y, X)\n",
    "\n",
    "    # ----- save as OME-TIFF (Fiji-compatible) -----\n",
    "    # Axes order TCZYX; Bio-Formats/Fiji will read as a 5D hyperstack\n",
    "    tiff.imwrite(\n",
    "        out_path,\n",
    "        hyper5,\n",
    "        bigtiff=True,\n",
    "        ome=True,\n",
    "        metadata={'axes': 'TCZYX'},  # optional: channel names via OME XML is more involved; axes is enough\n",
    "    )\n",
    "    print(f\"[saved] 5D hyperstack: {out_path}  shape={hyper5.shape}  axes=TCZYX\")\n",
    "\n",
    "# ===== usage =====\n",
    "# fixed_stack: (Z, Y, X) already in memory\n",
    "# save_path: path you previously wrote in build_hyperstack_uint8_in_memory (TZYX uint8)\n",
    "# out_5d: where to save the 5D hyperstack\n",
    "# Example:\n",
    "out_5d = START_FOLDER / \"fixed_plus_functional_5D.ome.tif\"\n",
    "build_5d_hyperstack_fixed_plus_func(fixed_stack, save_path, out_5d, T_expected=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9716b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import tifffile as tiff\n",
    "\n",
    "# Path to the 5D hyperstack you just wrote\n",
    "#path_5d = START_FOLDER / \"fixed_plus_functional_5D.ome.tif\"\n",
    "path_5d = out_5d\n",
    "\n",
    "# Open with tifffile\n",
    "stack5d = tiff.imread(path_5d)  # shape = (T, C, Z, Y, X)\n",
    "\n",
    "print(\"Loaded shape:\", stack5d.shape)  # should be (100, 2, Z, 512, 512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71812b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mask = START_FOLDER / \"f38_anatomy_00001_rotate_mask.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758e100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split channels: each -> (T, Z, Y, X)\n",
    "#fixed_TZYX = stack5d[:, 0]\n",
    "#func_TZYX  = stack5d[:, 1]\n",
    "\n",
    "mask = tiff.imread(p_mask).astype(bool)  # (Z,Y,X)\n",
    "\n",
    "# Broadcast mask over T dimension\n",
    "masked_func = stack5d[:, 1] * mask[None, ...]  # (T,Z,Y,X)\n",
    "masked_fixed = stack5d[:, 0] * mask[None, ...]\n",
    "\n",
    "\n",
    "# Set scale: (z, y, x) = (3, 1.1861, 1.1861) um\n",
    "scale = (3, 1.1861, 1.1861)\n",
    "\n",
    "\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add fixed first (background context)\n",
    "fixed_layer = viewer.add_image(\n",
    "    masked_fixed[0, ...],   # show first time-point initially\n",
    "    name=\"Fixed\",\n",
    "    colormap=\"gray\",\n",
    "    blending=\"translucent\",   # 2D/3D-friendly alpha blending\n",
    "    rendering=\"translucent\",  # for 3D: semi-transparent volume\n",
    "    opacity=0.28,\n",
    "    contrast_limits=(0, 255),\n",
    "    scale=scale,     # attach voxel size\n",
    ")\n",
    "# Add functional on top\n",
    "func_layer = viewer.add_image(\n",
    "    masked_func,\n",
    "    name=\"Functional\",\n",
    "    colormap=\"green\",\n",
    "    blending=\"additive\",      # bright signal pops through the fixed\n",
    "    rendering=\"mip\",          # for 3D: max-intensity through the center slab\n",
    "    opacity=1.0,\n",
    "    contrast_limits=(0, 255),\n",
    "    scale=scale,     # attach voxel size\n",
    ")\n",
    "\n",
    "viewer.dims.ndisplay = 3      # turn on 3D\n",
    "# Ensure Functional is above Fixed\n",
    "if viewer.layers.index(func_layer) < viewer.layers.index(fixed_layer):\n",
    "    viewer.layers.move(viewer.layers.index(func_layer), len(viewer.layers)-1)\n",
    "\n",
    "napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b04e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import napari\n",
    "import imageio as iio   # pip install imageio imageio-ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 1) Save / Load napari settings\n",
    "# ------------------------------\n",
    "\n",
    "def save_viewer_preset(viewer: napari.Viewer, folder: Path):\n",
    "    \"\"\"\n",
    "    Save key viewer settings (layer properties, dims, camera) to JSON files in `folder`.\n",
    "    \"\"\"\n",
    "    folder = Path(folder)\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Save per-layer props\n",
    "    layers_state = []\n",
    "    for lyr in viewer.layers:\n",
    "        entry = {\n",
    "            \"name\": lyr.name,\n",
    "            \"visible\": bool(lyr.visible),\n",
    "            \"opacity\": float(lyr.opacity),\n",
    "            \"blending\": str(getattr(lyr, \"blending\", \"\")),\n",
    "            \"colormap\": str(getattr(lyr, \"colormap\", \"\")),\n",
    "            \"contrast_limits\": list(map(float, getattr(lyr, \"contrast_limits\", (0, 1)))),\n",
    "            \"rendering\": str(getattr(lyr, \"rendering\", \"\")),\n",
    "            \"scale\": list(map(float, getattr(lyr, \"scale\", (1, 1, 1)))),\n",
    "        }\n",
    "        layers_state.append(entry)\n",
    "\n",
    "    dims_state = {\n",
    "        \"ndisplay\": int(viewer.dims.ndisplay),\n",
    "        \"current_step\": list(map(int, viewer.dims.current_step)),  # (… T, Z, Y, X)\n",
    "        \"order\": list(map(int, viewer.dims.order)),\n",
    "    }\n",
    "\n",
    "    cam = viewer.camera\n",
    "    camera_state = {\n",
    "        \"zoom\": float(cam.zoom),\n",
    "        \"center\": list(map(float, getattr(cam, \"center\", (0, 0, 0)))),\n",
    "        \"angles\": list(map(float, getattr(cam, \"angles\", (0, 0, 0)))),  # (elev, azim, roll)\n",
    "    }\n",
    "\n",
    "    with open(folder / \"layers.json\", \"w\") as f:\n",
    "        json.dump(layers_state, f, indent=2)\n",
    "    with open(folder / \"dims.json\", \"w\") as f:\n",
    "        json.dump(dims_state, f, indent=2)\n",
    "    with open(folder / \"camera.json\", \"w\") as f:\n",
    "        json.dump(camera_state, f, indent=2)\n",
    "\n",
    "    print(f\"[preset] Saved viewer settings to {folder}\")\n",
    "\n",
    "def load_viewer_preset(viewer: napari.Viewer, folder: Path):\n",
    "    \"\"\"\n",
    "    Restore dims + camera (non-destructive to layer data itself).\n",
    "    \"\"\"\n",
    "    folder = Path(folder)\n",
    "    if (folder / \"dims.json\").exists():\n",
    "        with open(folder / \"dims.json\") as f:\n",
    "            dims = json.load(f)\n",
    "        viewer.dims.ndisplay = dims.get(\"ndisplay\", viewer.dims.ndisplay)\n",
    "        # optional: restore current_step/order if shapes match\n",
    "        try:\n",
    "            viewer.dims.order = dims[\"order\"]\n",
    "            viewer.dims.current_step = dims[\"current_step\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if (folder / \"camera.json\").exists():\n",
    "        with open(folder / \"camera.json\") as f:\n",
    "            cam = json.load(f)\n",
    "        viewer.camera.zoom = cam.get(\"zoom\", viewer.camera.zoom)\n",
    "        if \"center\" in cam:\n",
    "            viewer.camera.center = cam[\"center\"]\n",
    "        if \"angles\" in cam:\n",
    "            viewer.camera.angles = cam[\"angles\"]\n",
    "\n",
    "    print(f\"[preset] Loaded viewer settings from {folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b946d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_fixed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d227104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------\n",
    "# 2) Movie recorder from napari\n",
    "# ------------------------------\n",
    "\n",
    "def record_movie_from_viewer(\n",
    "    viewer: napari.Viewer,\n",
    "    out_path: str = \"napari_movie.mp4\",\n",
    "    total_seconds: float = 10.0,\n",
    "    fps: int = 30,\n",
    "    step_every_n_frames: int = 2,             # advance time every 2 frames\n",
    "    size: tuple[int, int] = (640, 640),       # (W,H) — canvas-only render\n",
    "    rotate_camera: bool = True,\n",
    "    start_angles: tuple[float,float,float] | None = None,  # (elev, azim, roll)\n",
    "    end_angles:   tuple[float,float,float] | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Renders the current viewer scene to a video:\n",
    "      - Time advances one step every `step_every_n_frames` frames (loops if needed)\n",
    "      - 30fps default\n",
    "      - Canvas-only frames\n",
    "      - Optional gradual camera angle interpolation (3D)\n",
    "    \"\"\"\n",
    "    # Figure out number of frames and time-axis extent\n",
    "    n_frames = int(round(total_seconds * fps))\n",
    "    # Heuristic: assume first axis is time (T, Z, Y, X) for your layers\n",
    "    # If not, set time_axis manually here.\n",
    "    if len(viewer.dims.current_step) < 4:\n",
    "        raise RuntimeError(\"Expected at least 4 dims (T,Z,Y,X).\")\n",
    "\n",
    "    # We look for the time axis by checking which axis has >1 and is first in order by your setup.\n",
    "    # In your 5D stack added per-channel as separate layers: each layer is (T,Z,Y,X) -> time axis index 0.\n",
    "    time_axis = 0\n",
    "    T = viewer.layers[0].data.shape[time_axis]\n",
    "\n",
    "    # Camera angles\n",
    "    if rotate_camera and viewer.dims.ndisplay == 3:\n",
    "        ang0 = tuple(getattr(viewer.camera, \"angles\", (30.0, 45.0, 0.0))) if start_angles is None else start_angles\n",
    "        ang1 = (ang0[0]+30, ang0[1]+90, ang0[2]) if end_angles is None else end_angles\n",
    "    else:\n",
    "        ang0 = ang1 = tuple(getattr(viewer.camera, \"angles\", (0.0, 0.0, 0.0)))\n",
    "\n",
    "    # Prepare writer (H.264/MP4 via imageio-ffmpeg)\n",
    "    writer = iio.get_writer(out_path, fps=fps, codec=\"libx264\", quality=8)\n",
    "\n",
    "    try:\n",
    "        # prime\n",
    "        orig_angles = tuple(getattr(viewer.camera, \"angles\", (0.0, 0.0, 0.0)))\n",
    "\n",
    "        for f in range(n_frames):\n",
    "            # Advance time every N frames (loop)\n",
    "            t_idx = (f // step_every_n_frames) % T\n",
    "            curr = list(viewer.dims.current_step)\n",
    "            curr[time_axis] = t_idx\n",
    "            viewer.dims.current_step = tuple(curr)\n",
    "\n",
    "            # Interpolate camera angles (if 3D)\n",
    "            if rotate_camera and viewer.dims.ndisplay == 3:\n",
    "                alpha = f / max(n_frames - 1, 1)\n",
    "                viewer.camera.angles = [\n",
    "                    (1 - alpha) * ang0[i] + alpha * ang1[i] for i in range(3)\n",
    "                ]\n",
    "\n",
    "            # Grab canvas-only screenshot at requested size (W,H)\n",
    "            frame = viewer.screenshot(canvas_only=True, flash=False, size=size)\n",
    "            writer.append_data(frame)\n",
    "\n",
    "        # restore original camera\n",
    "        viewer.camera.angles = orig_angles\n",
    "\n",
    "    finally:\n",
    "        writer.close()\n",
    "\n",
    "    print(f\"[movie] Saved {out_path}  ({n_frames} frames @ {fps} fps ≈ {n_frames/fps:.2f}s)\")\n",
    "\n",
    "# ------------------------------\n",
    "# Usage\n",
    "# ------------------------------\n",
    "\n",
    "# 1) Save current settings so you can reuse from now on\n",
    "napariPresetsFolder =  START_FOLDER / \"napari_presets\"\n",
    "#START_FOLDER = Path(\"napari_presets\")\n",
    "save_viewer_preset(viewer, napariPresetsFolder)\n",
    "\n",
    "# (Later, you can restore with:)\n",
    "# load_viewer_preset(viewer, napariPresetsFolder)\n",
    "\n",
    "# 2) Record a movie (defaults: 10s, 30fps, time advance every 2 frames, 640x640)\n",
    "record_movie_from_viewer(\n",
    "    viewer,\n",
    "    out_path = START_FOLDER / \"hyperstack_demo.mp4\",\n",
    "    total_seconds=10.0,         # change this if you want longer/shorter\n",
    "    fps=30,\n",
    "    step_every_n_frames=2,      # time++ every 2 frames (=> 15 time-steps/sec)\n",
    "    size=(640, 640),            # near 512x512, better for players/codecs\n",
    "    rotate_camera=True,         # set False for a static camera\n",
    "    # start_angles=(30, 45, 0), # optional: set explicit start/end if you want\n",
    "    # end_angles=(60, 135, 0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f7899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
