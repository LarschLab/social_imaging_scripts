from __future__ import annotations

from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, Optional

from pydantic import BaseModel, ConfigDict, Field, field_validator

from ..metadata.config import normalise_pathlike, ProcessingLogConfig


class ArtefactRef(BaseModel):
    """Reference to an input or output artefact produced during processing."""

    model_config = ConfigDict(extra="ignore")

    kind: str = Field(
        default="file",
        description="High-level artefact category (e.g., file, folder, table).",
    )
    path: Path = Field(description="Filesystem location of the artefact.")
    description: Optional[str] = Field(
        default=None, description="Optional human-readable context for the artefact."
    )

    @classmethod
    def from_path(cls, path: Path, kind: str = "file", description: Optional[str] = None) -> "ArtefactRef":
        return cls(kind=kind, path=Path(path), description=description)

    @field_validator("path", mode="before")
    @classmethod
    def _normalise_path(cls, value):
        return normalise_pathlike(value)


class StageRecord(BaseModel):
    """Structured record describing the outcome of a processing stage."""

    model_config = ConfigDict(extra="ignore")

    status: str = Field(
        default="success", description="Outcome status (success, skipped, failed)."
    )
    run_id: Optional[str] = Field(
        default=None, description="Identifier for the pipeline run that produced this record."
    )
    started_at: Optional[datetime] = Field(
        default=None, description="UTC timestamp when processing started."
    )
    completed_at: Optional[datetime] = Field(
        default=None, description="UTC timestamp when processing completed."
    )
    parameters: Dict[str, Any] = Field(
        default_factory=dict,
        description="Resolved parameter values used during stage execution.",
    )
    inputs: Dict[str, ArtefactRef] = Field(
        default_factory=dict,
        description="Artefacts consumed by this stage keyed by logical name.",
    )
    outputs: Dict[str, ArtefactRef] = Field(
        default_factory=dict,
        description="Artefacts generated by this stage keyed by logical name.",
    )
    notes: Optional[str] = Field(
        default=None, description="Optional free-form notes or error context."
    )


class AnimalProcessingLog(BaseModel):
    """Aggregate processing records for a single animal."""

    model_config = ConfigDict(extra="ignore")

    animal_id: str
    pipeline_version: Optional[str] = Field(
        default=None, description="Semantic version or git SHA of the pipeline."
    )
    last_updated: datetime = Field(
        default_factory=lambda: datetime.now(tz=timezone.utc),
        description="Timestamp of the last update to this log.",
    )
    stages: Dict[str, StageRecord] = Field(
        default_factory=dict,
        description="Mapping between stage identifiers and their execution records.",
    )

    def touch(self) -> None:
        """Update the last_updated timestamp to now."""

        self.last_updated = datetime.now(tz=timezone.utc)

    def ensure_stage(self, stage: str) -> StageRecord:
        """Ensure a stage record exists and return it."""

        if stage not in self.stages:
            self.stages[stage] = StageRecord()
        return self.stages[stage]


def build_processing_log_path(cfg: ProcessingLogConfig, animal_id: str, base_dir: Path) -> Path:
    """Resolve the path for the processing log of *animal_id*."""

    directory = Path(cfg.directory or "metadata/processed")
    directory = normalise_pathlike(directory) or directory
    if not directory.is_absolute():
        directory = Path(base_dir) / directory
    filename = cfg.filename_template.format(animal_id=animal_id)
    return directory / filename


def load_processing_log(path: Path) -> AnimalProcessingLog:
    """Load an animal processing log from *path*."""

    from ruamel.yaml import YAML

    yaml = YAML(typ="safe")
    data = yaml.load(Path(path).read_text(encoding="utf-8")) or {}
    return AnimalProcessingLog.model_validate(data)


def save_processing_log(log: AnimalProcessingLog, path: Path) -> None:
    """Serialize *log* to *path* in YAML format."""

    from ruamel.yaml import YAML

    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)
    yaml = YAML()
    yaml.default_flow_style = False
    yaml.dump(log.model_dump(mode="json"), path.open("w", encoding="utf-8"))
